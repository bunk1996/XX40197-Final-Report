\chapter{Discussion}

\section{Symbol Recovery Capabilities and Limitations}
\subsection{Real World Signal Characteristics}
The analysis of the real world data recordings highlight the robustness of the data. The exemplar dataset used shows unusually high levels of lightning activity that can be clearly characterised as continuous and impulsive, through looking at the time series output of the developed noise estimation routine. Additionally the recovered baseband signals clearly show the expected underlying characteristics of an MSK signal.  
\\\\
When estimating the BER of these recorded signals two potential limitations, firstly a double bit error relating to symbols with opposite signs can cancel out an error in the estimation process. Secondly a less prevalent but also potential issue is during the unwrapping process the interference causes a $2\pi$ jump in phase which results in a miscalculation of symbols present. This can be easily avoided my linearly shifting the phase so that turning points lie away from $\pm\pi$ boundary, if this still proves to be an issue. There are adaptive methods that can be recursively applied to locally move points away from the $\pm\pi$ boundary. 
\\\\
Equally the effect of clipping means that the SNR estimate becomes somewhat arbitrary because the impact of the lightning is not equally represented across all the transmitters.

\subsection{Simulation Tools}
The simulation tools provided a powerful tool to simulate the VLF transmissions in the recorded data. This was closely validated by comparing the the output of the simulation. The designed simulator is capable of replicating noise distribution present in a a dataset that it is intended to imitate. This does have to be implemented with additional gains in this particular instance because the data does not fully represent the magnitude of the lightning, due to limitations introduced by clipping during data acquisition. 
\\\\
The techniques applied to implement this tool show their flexibility and usefulness as they produce the expected signals with the varying characteristics that are shown by the recorded data. Especially with regards to amplitude distribution and similar power spectral distribution. However it is slightly limited in it's ability to represent the relative amplitude of noise to transmitter independently.
\\\\
The primary contribution of this tool was to provide the ability to vary the nature of the interference present in the signal in order to identify what characteristics give rise to a bit error.

\subsection{Symbol Recovery}
The techniques involved in signal recovery show promising results, the algorithm utilising the known properties of an MSK shows good results for all signals, however it is desirable for all bit loss to be mitigated. The types of bit loss fall into two categories: A leading bit loss this is where the an event causes a phase change that appears roughly in the same place as a bit transition might and causes a premature symbol change. The other type is a missed transition, this is when a single symbol is missed when it is sandwiched within a long sequence of opposite symbols as a lightning event removes the prominence of the characteristic relating to that transition within the data. The errors typically occur on the trailing end of a lightning event.
\\\\
Although it is easy to quantify the bit error during simulation as the signal is known, because the ultimate objective is to maximise the number of bits recovered it is necessary to be able to isolate temporal position of the error. Several metrics have been proposed in order to isolate certain signal characteristics based on spacial proximity to a transition point and analysis of local area statistics. The output of these analyses provides thresholds which can be applied to help narrow down where in the time series a bit error is likely to have occurred.
\\\\
The comparison of SNR and BER proves only a useful metric when used exclusively within the two separate domains because the simulated signals appear to exhibit much more resilience to the impulsive noise than the real data. As the estimated BER was much higher relative to the SNR in the simulated signals. This observation is of little surprise as the lightning is near instantaneous relative to the signal, the simulations have very intensive 'lightning' present and as previously established, not every lightning event causes a bit loss. Compared the work of \cite{Yang2016} a much higher resilience to SNR is shown. Much lower SNR values give equivalent bit recovery.
\\\\
Error correction remains a limitation of the investigation, although the two metrics that were explored provide the ability to identify elements of the signal occurred. The investigation was somewhat unsuccessful in using these techniques in a modified version of the algorithm developed. This by no means is a conclusion that bit recovery is impossible however due as the problem has a random element there are parts of the signal that exhibit apparently less than ideal properties can equally not be responsible for bit loss. 

\section{Errors and Uncertainties}
There is an uncertainty that needs to be addressed relating to the nature of the simulated lightning noise compared to the reality. Although best efforts have been mate to replicate the noise based of observable characteristics and previous research. However for the purpose of this investigation the estimation was deemed to be as the results were representative enough to what was shown in the real data. 
\\\\
Another key uncertainty that is present in this investigation comes from the random nature of the problem, in that not all lightning events results in a bit loss. This introduces a huge amount of uncertainty when trying to isolate where the bit errors as the impact of the lightning is dependant on the relative state of the lightning and transmitter as to what the absolute impact on the signal is.
\\\\
The main errors in the exercise have been isolated as those present in the estimation methods used on the real signal. As there is only a limited amount of information that can be recovered from the received signals, the original message is not one of those. Therefore as an estimation of what the message may consist of provides a good gauge of what is happening however for very noisy signals there is a high probability that a double error may occur or additionally the corrupted nature of the signal may make the assumptions invalid.

\section{Wider Implications}
The results of this investigation use a simpler method of bit extraction compared to a lot of the literature and achieve similar results, when relating directly to the real data in particular \cite{Yang2016}. However although across communications a normalised SNR is a typical comparison metric. In this investigation it is shown that potentially a more localised metric is required for long bit sequences as lightning is typically short lived and highly impulsive therefore over a prolonged time period it is likely to have very little impact on the overall SNR. 
\\\\
Regarding the practical application of VLF communications, in general wireless transmission methods with potential for high BER have increasingly complex encryption. Which increases processing time at the transmitter and the receiver in addition to increasing message length. In simple terms high bit error rate results in the requirement for more data to be transmitted. Therefore the ability to recover more of the bit structure from the received signal using non-data related methods to reduce bit errors has a twofold advantage of allowing the complexity of encryption to be reducing the amount of data needing to be transmitted. Reducing the amount of data to be received with a robust reception method inherently reduces the chance of a bit error. The other advantage is the operational advantage to the submarines, currently the error correction method is implicit as the transmitters repeat the message constantly. Although it is difficult to eliminate this process on the basis that due to operational constraints there may be periods of time where a submarine cannot be at the appropriate depth to receive communications. However a robust receiver will prevent the submarine from having to remain shallow for any longer than necessary, as long messages take a long time to transmit which could require the submarine to remain shallow for three or four times longer in order to ensure that they have received a complete transmission.