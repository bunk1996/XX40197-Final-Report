\chapter{Discussion}

\section{Symbol Recovery Capabilities and Limitations}
\subsection{Real World Signal Characteristics}
The analysis of the real world data recordings highlight the robustness of the data. The exemplar dataset used shows unusually high levels of lightning activity that can be clearly characterised as continuous and impulsive, through looking at the time series output of the developed noise estimation routine. Additionally the recovered baseband signals clearly show the expected underlying characteristics of an MSK signal.  
\\\\
When estimating the BER of these recorded signals there are two potential limitations. Firstly a double bit error relating to symbols with opposite signs can cancel out an error in the estimation process. Secondly a less prevalent but also potential issue is during the unwrapping process the interference causes a $2\pi$ jump in phase which results in a miscalculation of symbols present. This can be easily avoided by shifting the phase so that turning points lie away from $\pm\pi$ boundary, if this still proves to be an issue. There are adaptive methods that can be recursively applied to locally move points away from the $\pm\pi$ boundary. 
\\\\
Equally the effect of clipping means that the SNR estimate becomes somewhat arbitrary because the impact of the lightning is not equally represented across all the transmitters, as it should be.

\subsection{Simulation Tools}

The simulation tools provided a powerful tool to simulate the VLF transmissions in the recorded data. This was closely validated by comparing the the output of the simulation. The designed simulator is capable of replicating noise distribution present in a a dataset that it is intended to imitate. This does have to be implemented with additional gains in this particular instance because the data does not fully represent the magnitude of the lightning, due to limitations introduced by clipping during data acquisition. However it does provide an excellent facility to assess the limitations of MSK and bit recovery.
\\\\
The techniques applied to implement this tool show their flexibility and usefulness. They produce the expected signals with the varying characteristics similar to those shown by the recorded data. Especially with regards to amplitude distribution and similar power spectral density.
\\\\
The primary contribution of this tool was to provide the ability to vary the nature of the interference present in the signal in order to identify what characteristics give rise to a bit error.

\subsection{Symbol Recovery}
The techniques involved in signal recovery show promising results, the algorithm utilising the known properties of an MSK shows good results for all signals, however it is desirable for all bit loss to be mitigated.

There are two types of bit loss. The first is when the lightning event causes a premature transition, this is when there is an apparent phase change in the correct place. The other is when there is a single opposite symbol in a long sequence of symbol. The lightning can often cause these symbols to be missed. The errors typically occur on the trailing end of a lightning event see figure \ref{fig:noiseamp}.
\\\\
Although it is easy to quantify the bit error during simulation as the signal is known, because the ultimate objective is to maximise the number of bits recovered it is necessary to be able to isolate temporal position of the error. Several metrics have been proposed in order to isolate certain signal characteristics based on spacial proximity to a transition point and analysis of local area statistics. The output of these analyses provides thresholds which can be applied to help narrow down where in the time series a bit error is likely to have occurred.
\\\\
The comparison of SNR and BER proves only a useful metric when used exclusively within the two separate domains because the simulated signals appear to exhibit much more resilience to the impulsive noise than the real data. As the estimated BER was much higher relative to the SNR in the simulated signals. This observation is of little surprise as the lightning is near instantaneous relative to the signal, the simulations have very intensive 'lightning' present and as previously established, not every lightning event causes a bit loss. Compared the work of \cite{Yang2016} a much higher resilience to SNR is shown. Much lower SNR values give equivalent bit recovery.
\\\\
The error correction implemented involved the development of two local area statistics from the data to investigate the signal properties at each calculated bit transition.  

\section{Errors and Uncertainties}
There is an uncertainty that needs to be addressed relating to the nature of the simulated lightning noise compared to the reality. Although best efforts have been mate to replicate the noise based of observable characteristics and previous research. However for the purpose of this investigation the estimation was deemed to be as the results were representative enough to what was shown in the real data. 
\\\\
Another key uncertainty that is present in this investigation comes from the random nature of the problem, in that not all lightning events results in a bit loss. This introduces a huge amount of uncertainty when trying to isolate where the bit errors as the impact of the lightning is dependant on the relative state of the lightning and transmitter as to what the absolute impact on the signal is.
\\\\
The main errors in the exercise have been isolated as those present in the estimation methods used on the real signal. As there is only a limited amount of information that can be recovered from the received signals, the original message is not one of those. Therefore as an estimation of what the message may consist of provides a good gauge of what is happening however for very noisy signals there is a high probability that a double error may occur or additionally the corrupted nature of the signal may make the assumptions invalid.

\section{Wider Implications}
The results of this investigation use a simpler method of bit extraction compared to a lot of the literature and achieve similar results, when relating directly to the real data in particular \cite{Yang2016}. However although across communications a normalised SNR is a typical comparison metric. In this investigation it is shown that potentially a more localised metric is required for long bit sequences as lightning is typically short lived and highly impulsive therefore over a prolonged time period it is likely to have very little impact on the overall SNR. 
\\\\
Regarding the practical application of VLF communications, in general wireless transmission methods with potential for high BER have increasingly complex encryption. Which increases processing time at the transmitter and the receiver in addition to increasing message length. In simple terms high bit error rate results in the requirement for more data to be transmitted. Therefore the ability to recover more of the bit structure from the received signal using non-data related methods to reduce bit errors has a twofold advantage of allowing the complexity of encryption to be reducing the amount of data needing to be transmitted. Reducing the amount of data to be received with a robust reception method inherently reduces the chance of a bit error. The other advantage is the operational advantage to the submarines, currently the error correction method is implicit as the transmitters repeat the message constantly. Although it is difficult to eliminate this process on the basis that due to operational constraints there may be periods of time where a submarine cannot be at the appropriate depth to receive communications. However a robust receiver will prevent the submarine from having to remain shallow for any longer than necessary, as long messages take a long time to transmit which could require the submarine to remain shallow for three or four times longer in order to ensure that they have received a complete transmission.